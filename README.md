# ğŸš€ ETL Jira â†’ BigQuery â†’ Looker

Este proyecto implementa un pipeline **ETL** para extraer informaciÃ³n de **Jira**, transformarla y cargarla en **BigQuery**, con el objetivo de habilitar reporting en **Looker / Power BI**.  

---

## ğŸ“‚ Estructura del proyecto
Jira_Solu/
â”‚â”€â”€ bigquery/           # Funciones de conexiÃ³n y queries (MERGE)
â”‚â”€â”€ etl/                # Extractor, Transformer, Loader (ETL)
â”‚â”€â”€ funciones/          # Conexiones especÃ­ficas a APIs (Jira)
â”‚â”€â”€ schema/             # DefiniciÃ³n de esquemas BigQuery
â”‚â”€â”€ utils/              # Logger y notificaciones
â”‚â”€â”€ credenciales/       # (Ignorado en git) JSON de servicio GCP
â”‚â”€â”€ main.py             # Script principal de orquestaciÃ³n
â”‚â”€â”€ .env.example        # Variables de entorno (plantilla)
â”‚â”€â”€ requirements.txt    # Dependencias Python
â”‚â”€â”€ README.md           # Este archivo

---

## âš™ï¸ ConfiguraciÃ³n del entorno

1. **Clonar el repo**  
git clone <repo-url>
cd Jira_Solu

2. **Crear entorno virtual**
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

3. **Instalar dependencias**
pip install -r requirements.txt

4.	**Configurar variables de entorno**
Copiar el archivo de ejemplo y completarlo con tus credenciales:

cp .env.example .env

**ğŸ”‘ Variables de entorno** (.env)

PROJECT_ID=data-warehouse-311917
DATASET_FINAL=Jira
DATASET_TEMP=zt_Jira_temp
BQ_LOCATION=US

JIRA_EMAIL=tu_email@dominio.com
JIRA_API_TOKEN=xxxxxxxxxxxxxxxxxx

DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/xxx/yyy

GOOGLE_APPLICATION_CREDENTIALS=./credenciales/data-warehouse-311917.json

**â–¶ï¸ EjecuciÃ³n**

Correr ETL manualmente

python main.py

EjecuciÃ³n histÃ³rica

python main.py --historico

**ğŸ› ï¸ Componentes ETL**
	â€¢	Extractor: descarga proyectos, sprints y tickets desde Jira.
	â€¢	Transformer: limpia y normaliza los datos (ej. estimates a horas).
	â€¢	Loader: carga los datos en BigQuery (dataset temporal + MERGE).

